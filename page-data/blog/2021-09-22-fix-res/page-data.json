{"componentChunkName":"component---src-components-jupyter-blog-layout-js","path":"/blog/2021-09-22-fix-res/","result":{"data":{"jupyterNotebook":{"id":"a5ddaf24-8d02-5505-8cb3-33549fb3fbb3 >>> JupyterNotebook","html":"<div class=\"notebook-render\"><div class=\"sc-ifAKCX zMCZx\"><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h1>Understanding FixRes - Fixing the train-test resolution discrepancy</h1>\n<h2>Introduction</h2>\n<p>In this blog post we will try to understand the ideas introduced in the <a href=\"https://arxiv.org/pdf/1906.06423.pdf\">FixRes paper</a> published by the Facebook AI Research team.</p>\n<p>We will implement the method described in the paper while training a ResNet-50 model from scratch in PyTorch, on the <a href=\"https://www.kaggle.com/c/cassava-leaf-disease-classification\">Cassava leaf disease classification dataset</a> from Kaggle.</p>\n<p>Finally, we will see how we can use this method in fast.ai with transfer learning.</p>\n<h2>The train-test resolution discrepancy</h2>\n<p>The paper shows that existing data augmentation techniques introduces a significant difference in sizes of objects that a CNN sees during training and testing.</p>\n<p>During training, it is common to extract/crop a random region of classification from an image and then resize it to a resolution that is compatible with the CNN architecture.</p>\n<p>For example, the crop would be resized to 224 x 224 when using AlexNet. However, some architectures like ResNet don&#x27;t have such a requirement. Even in this case, all images within a batch need to be resized to a common resolution.</p>\n<p>This kind of augmentation is what we get with <code>RandomResizedCrop</code> in PyTorch.</p>\n<p><img src=\"/rrc.png\"/></p>\n<p><em>(<a href=\"https://pystyle.info/pytorch-list-of-transforms/\">Source</a>) RandomResizedCrop randomly selects different areas in the input image and resizes them to the same size.</em></p>\n<p>During testing, however, we just extract a center crop of the size we would like to feed to the model.</p>\n<p>The result of this difference during training and testing is this:</p>\n<p><img src=\"/ttrd.png\"/></p>\n<p>This image shows that although we are providing the same resolution of images to the model during training and testing, the scale of horses that the model sees during these phases is different.</p>\n<p>This is because the nature of preprocessing used tends to zoom on objects, resulting in a larger horse during training compared to testing.</p>\n<p>This is a problem because convolutional neural networks do not have &quot;built-in scale invariance&quot;, i.e. they are sensitive to the sizes of objects in the images used to train them.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Fixing the apparent object size problem</h2>\n<p>To fix this discrepancy in the apparent size of objects during training and testing, the authors propose two options:</p>\n<ol>\n<li><strong>Decrease</strong> the resolution of images during <strong>training</strong>.</li>\n<li><strong>Increase</strong> the resolution of images during <strong>testing</strong>.</li>\n</ol>\n<p>As a result, the model will see horses of the same size.</p>\n<p>The authors found that the ratio of the size of objects seen at test time to size of objects seen at train time lies between between 0.28 and 1.</p>\n<p>This means that during test time, some objects may appear to be just a third of their size during training time!</p>\n<p>With standard pre-processing, the authors claim that objects at test time are on average 0.8 times what they appear at training time.</p>\n<p>This means that if we choose to decrease the resolution of images during training, we need to make it 0.8 times the resolution we use during training.</p>\n<p>If we choose to increase the resolution of images during testing instead, then we need to make them <span class=\"inlineMath\"><span class=\"katex\"><span class=\"katex-mathml\"><semantics><mrow><mn>1</mn><mi mathvariant=\"normal\">/</mi><mn>0.8</mn><mo>=</mo><mn>1.25</mn></mrow><annotation encoding=\"application/x-tex\">1/0.8 = 1.25</annotation></semantics></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em\"></span><span class=\"mord\">1</span><span class=\"mord\">/</span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">8</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span></span> times the resolution used during training.</p>\n<p>For example, if we have images of resolution 224 x 224, we could adjust the resolution in one of the following ways:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Resolution at training time</th>\n<th>Resolution at test time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Decrease resolution at training time</td>\n<td><span class=\"inlineMath\"><span class=\"katex\"><span class=\"katex-mathml\"><semantics><mrow><mn>0.8</mn><mo>×</mo><mn>224</mn><mo>=</mo><mn>179</mn></mrow><annotation encoding=\"application/x-tex\">0.8 \\times 224 = 179</annotation></semantics></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">8</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">2</span><span class=\"mord\">2</span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">1</span><span class=\"mord\">7</span><span class=\"mord\">9</span></span></span></span></span></td>\n<td><span class=\"inlineMath\"><span class=\"katex\"><span class=\"katex-mathml\"><semantics><mrow><mn>224</mn></mrow><annotation encoding=\"application/x-tex\">224</annotation></semantics></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">2</span><span class=\"mord\">2</span><span class=\"mord\">4</span></span></span></span></span></td>\n</tr>\n<tr>\n<td>Increase resolution at training time</td>\n<td><span class=\"inlineMath\"><span class=\"katex\"><span class=\"katex-mathml\"><semantics><mrow><mn>224</mn></mrow><annotation encoding=\"application/x-tex\">224</annotation></semantics></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">2</span><span class=\"mord\">2</span><span class=\"mord\">4</span></span></span></span></span></td>\n<td><span class=\"inlineMath\"><span class=\"katex\"><span class=\"katex-mathml\"><semantics><mrow><mn>224</mn><mo>∗</mo><mn>1.25</mn><mo>=</mo><mn>280</mn></mrow><annotation encoding=\"application/x-tex\">224 * 1.25 = 280</annotation></semantics></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">2</span><span class=\"mord\">2</span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\">2</span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em\"></span><span class=\"mord\">2</span><span class=\"mord\">8</span><span class=\"mord\">0</span></span></span></span></span></td>\n</tr>\n</tbody>\n</table>\n<p><em>Table 1: Adjusted training and test resolutions for images of size 224x224</em></p>\n<p>Wouldn&#x27;t life be so wonderful if everything &quot;just worked&quot; when we did this?</p>\n<p>Unfortunately, the authors discovered that changing the resolution of images during testing significantly skews the distribution of activations in the model.</p>\n<p><img src=\"/act-dist.png\"/></p>\n<p>This graph shows the cumulative density of activations after average pooling layer for a ResNet-50 trained at a resolution of 224 and tested at the different resolutions shown.</p>\n<p>As we can see, lower resolutions result in more activations being 0 and activations are more spread out. At higher resolutions, we see the opposite - the number of 0 activations drops and the activations are less spread out.</p>\n<p>If the distribution of activations significantly change at test time, their values will not be in the range that the final classifier was trained for. As a result, the accuracy of the model will suffer.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Fixing the skewed activation statistics</h2>\n<p>When the distributions of activations change as described in the previous section, the last few layers of the network are affected most.</p>\n<p>The earlier layers of a convolutional neural network that consist of convolutions, activations and other similar layers remain largely unaffected.</p>\n<p>The authors mention two ways to deal with these skewed activations:</p>\n<ol>\n<li>Parametric adaptation</li>\n<li>Fine-tuning</li>\n</ol>\n<p>The authors mention that parametric adaptation provided a measurable but limited improvement in accuracy. Therefore, we&#x27;ll focus on how to fine-tune the model instead.</p>\n<p>A change in resolution of images at test time is effectively a domain shift, and a common way to deal with domain shift is fine-tuning the model.</p>\n<p>When fine-tuning the model we use the same images from the training set but with a higher resolution.</p>\n<p>The authors also mention that we need to fine-tune the last few layers of the model which includes any batch normalization layer that precedes the pooling layer.</p>\n<p><img src=\"/bn-ft.png\"/></p>\n<p>The dotted green line in the image shows the distribution of activations when using the same resolution of images for training and testing.</p>\n<p>The blue line shows the distribution when we use larger images for testing without fine tuning the last batch normalization layer.</p>\n<p>The orange line shows the distrbution after the last batch normalization layer has been fine-tuned. It shows a distribution that is almost identical to the dotted green line.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Training a model using PyTorch</h2>\n<p>We will now test the effectiveness of this method using the <a href=\"https://www.kaggle.com/c/cassava-leaf-disease-classification\">Cassava leaf disease classification dataset</a> from Kaggle.</p>\n<p>We will first train a baseline model and then compare its performance with another one we train using the FixRes method.</p>\n<h3>Baseline model</h3></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">import</span><span> pandas </span><span class=\"token\" style=\"color:#0000ff\">as</span><span> pd\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> torch\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>nn </span><span class=\"token\" style=\"color:#0000ff\">as</span><span> nn\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>optim </span><span class=\"token\" style=\"color:#0000ff\">as</span><span> optim\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">from</span><span> torchvision </span><span class=\"token\" style=\"color:#0000ff\">import</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">,</span><span> models\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">from</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>utils</span><span class=\"token\" style=\"color:#393A34\">.</span><span>data </span><span class=\"token\" style=\"color:#0000ff\">import</span><span> Dataset</span><span class=\"token\" style=\"color:#393A34\">,</span><span> DataLoader\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">from</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>optim </span><span class=\"token\" style=\"color:#0000ff\">import</span><span> lr_scheduler\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">from</span><span> PIL </span><span class=\"token\" style=\"color:#0000ff\">import</span><span> Image\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> copy\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> os\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> time\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Ignore warnings to keep the output nice and pretty</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">import</span><span> warnings\n</span><span>warnings</span><span class=\"token\" style=\"color:#393A34\">.</span><span>filterwarnings</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&quot;ignore&quot;</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>The train-test split being used was created in a <a href=\"https://community.wandb.ai/c/community-events/fastbook/8\">Fastbook reading group</a> and can be found <a href=\"https://www.kaggle.com/aroraaman/wandbcassava\">here</a>.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>df </span><span class=\"token\" style=\"color:#393A34\">=</span><span> pd</span><span class=\"token\" style=\"color:#393A34\">.</span><span>read_csv</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&#x27;../wandb_cassava_train_val_split.csv&#x27;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>head</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><div><div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n      <th>is_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000015157.jpg</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000201771.jpg</td>\n      <td>3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100042118.jpg</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000723321.jpg</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000812911.jpg</td>\n      <td>3</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div></div></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We first create a <code>Dataset</code> for the data.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">class</span><span> </span><span class=\"token\" style=\"color:#2B91AF\">CassavaDataset</span><span class=\"token\" style=\"color:#393A34\">(</span><span>Dataset</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">__init__</span><span class=\"token\" style=\"color:#393A34\">(</span><span>self</span><span class=\"token\" style=\"color:#393A34\">,</span><span> df</span><span class=\"token\" style=\"color:#393A34\">,</span><span> root_dir</span><span class=\"token\" style=\"color:#393A34\">,</span><span> transform</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">None</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>df </span><span class=\"token\" style=\"color:#393A34\">=</span><span> df\n</span><span>        self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>root_dir </span><span class=\"token\" style=\"color:#393A34\">=</span><span> root_dir\n</span><span>        self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>transform</span><span class=\"token\" style=\"color:#393A34\">=</span><span>transform\n</span>        \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">__len__</span><span class=\"token\" style=\"color:#393A34\">(</span><span>self</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> </span><span class=\"token builtin\">len</span><span class=\"token\" style=\"color:#393A34\">(</span><span>self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>df</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">__getitem__</span><span class=\"token\" style=\"color:#393A34\">(</span><span>self</span><span class=\"token\" style=\"color:#393A34\">,</span><span> idx</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>is_tensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span>idx</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>            idx </span><span class=\"token\" style=\"color:#393A34\">=</span><span> idx</span><span class=\"token\" style=\"color:#393A34\">.</span><span>tolist</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We get the path of the image</span><span>\n</span><span>        img_path </span><span class=\"token\" style=\"color:#393A34\">=</span><span> os</span><span class=\"token\" style=\"color:#393A34\">.</span><span>path</span><span class=\"token\" style=\"color:#393A34\">.</span><span>join</span><span class=\"token\" style=\"color:#393A34\">(</span><span>self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>root_dir</span><span class=\"token\" style=\"color:#393A34\">,</span><span> self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>iloc</span><span class=\"token\" style=\"color:#393A34\">[</span><span>idx</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We load the image and label</span><span>\n</span><span>        image </span><span class=\"token\" style=\"color:#393A34\">=</span><span> Image</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">open</span><span class=\"token\" style=\"color:#393A34\">(</span><span>img_path</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>        label </span><span class=\"token\" style=\"color:#393A34\">=</span><span> self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>iloc</span><span class=\"token\" style=\"color:#393A34\">[</span><span>idx</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">1</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We create a single &quot;sample&quot; with the image and its label</span><span>\n</span><span>        sample </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span class=\"token\" style=\"color:#A31515\">&quot;image&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> image</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&quot;label&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> label</span><span class=\"token\" style=\"color:#393A34\">}</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We apply transforms if specified</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>transform</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>            sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;image&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span> </span><span class=\"token\" style=\"color:#393A34\">=</span><span> self</span><span class=\"token\" style=\"color:#393A34\">.</span><span>transform</span><span class=\"token\" style=\"color:#393A34\">(</span><span>sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;image&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> sample</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We then define the augmentation we&#x27;ll use during training and testing.</p>\n<p>As you can see, we use <code>RandomResizedCrop</code> during training and <code>CenterCrop</code> during testing with the same size.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>data_transforms </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&#x27;train&#x27;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Compose</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">[</span><span>\n</span><span>            </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># RandomResizedCrop of size 224 used during training</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>RandomResizedCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">224</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>RandomHorizontalFlip</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>ToTensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&#x27;val&#x27;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Compose</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">[</span><span>\n</span><span>            </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># CenterCrop of size 224 used during testing</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>CenterCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">224</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>ToTensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">}</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We can now create training and validation datasets.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">get_datasets</span><span class=\"token\" style=\"color:#393A34\">(</span><span>data_transforms</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We create a training dataset using rows in our data file that have `is_val` equal to False</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># using the transforms we have created above for training...</span><span>\n</span><span>    train_ds </span><span class=\"token\" style=\"color:#393A34\">=</span><span> CassavaDataset</span><span class=\"token\" style=\"color:#393A34\">(</span><span>df</span><span class=\"token\" style=\"color:#393A34\">[</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>is_val </span><span class=\"token\" style=\"color:#393A34\">==</span><span> </span><span class=\"token\" style=\"color:#36acaa\">False</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>reset_index</span><span class=\"token\" style=\"color:#393A34\">(</span><span>drop</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;../train_images&#x27;</span><span class=\"token\" style=\"color:#393A34\">,</span><span> data_transforms</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;train&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and a test dataset with rows that have `is_val` equal to True,</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># using the transforms we have created above for testing.</span><span>\n</span><span>    val_ds </span><span class=\"token\" style=\"color:#393A34\">=</span><span> CassavaDataset</span><span class=\"token\" style=\"color:#393A34\">(</span><span>df</span><span class=\"token\" style=\"color:#393A34\">[</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>is_val </span><span class=\"token\" style=\"color:#393A34\">==</span><span> </span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>reset_index</span><span class=\"token\" style=\"color:#393A34\">(</span><span>drop</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;../train_images&#x27;</span><span class=\"token\" style=\"color:#393A34\">,</span><span> data_transforms</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;val&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> train_ds</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> val_ds\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">}</span><span>\n</span>\n<span>datasets </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_datasets</span><span class=\"token\" style=\"color:#393A34\">(</span><span>data_transforms</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>dataset_sizes </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>x</span><span class=\"token\" style=\"color:#393A34\">:</span><span> </span><span class=\"token builtin\">len</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">[</span><span>x</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> x </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> </span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;train&#x27;</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;val&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">}</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>The next step is to create data loaders for these datasets.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">get_dataloaders</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">,</span><span> bs</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">64</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We create dataloaders from the datasets to enable retrieval of data in batches,</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># to shuffle the data at every epoch, and to parallelize data retrieval (using 4 workers in this case)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> DataLoader</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> batch_size</span><span class=\"token\" style=\"color:#393A34\">=</span><span>bs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> shuffle</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">,</span><span> num_workers</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">4</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> DataLoader</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> batch_size</span><span class=\"token\" style=\"color:#393A34\">=</span><span>bs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> shuffle</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">,</span><span> num_workers</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">4</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">}</span><span>\n</span>\n<span>dataloaders </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_dataloaders</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We now create three utility methods:</p>\n<ol>\n<li><code>train_loop</code> to train the model for one epoch</li>\n<li><code>eval_loop</code> to evaluate the model on validation data for one epoch</li>\n<li><code>train</code> to call <code>train_loop</code> and <code>eval_loop</code> for the number of epochs specified, and also to keep track of the best model weights.</li>\n</ol></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">train_loop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> optimizer</span><span class=\"token\" style=\"color:#393A34\">,</span><span> ds_size</span><span class=\"token\" style=\"color:#393A34\">,</span><span> fine_tune</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We will use the `fine_tune` parameter to ensure that we are</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># modifying only the last batch normalization layer.</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> fine_tune</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        model</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">eval</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>        model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>layer4</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#36acaa\">2</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>bn3</span><span class=\"token\" style=\"color:#393A34\">.</span><span>train</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Otherwise, we put the model in `train` mode</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># so that all batch normalization layers are updated</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">else</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>train</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We keep a track of the loss over all batches in an epoch</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># to later calculate the average loss...</span><span>\n</span><span>    running_loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0.0</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and we also keep track of how many correct predictions the</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># model makes to later calculate the average accuracy.</span><span>\n</span><span>    running_corrects </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We then loop through every batch in an epoch</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> sample </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> dataloader</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Extract the images...</span><span>\n</span><span>        inputs </span><span class=\"token\" style=\"color:#393A34\">=</span><span> sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;image&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>to</span><span class=\"token\" style=\"color:#393A34\">(</span><span>device</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and their corresponding labels</span><span>\n</span><span>        labels </span><span class=\"token\" style=\"color:#393A34\">=</span><span> sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;label&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>to</span><span class=\"token\" style=\"color:#393A34\">(</span><span>device</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Boilerplate PyTorch training code:</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 1. Reset all gradients through optimizer</span><span>\n</span><span>        optimizer</span><span class=\"token\" style=\"color:#393A34\">.</span><span>zero_grad</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 2. Feed model inputs and capture outputs</span><span>\n</span><span>        outputs </span><span class=\"token\" style=\"color:#393A34\">=</span><span> model</span><span class=\"token\" style=\"color:#393A34\">(</span><span>inputs</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 3. Calculate class predicted by model</span><span>\n</span><span>        _</span><span class=\"token\" style=\"color:#393A34\">,</span><span> preds </span><span class=\"token\" style=\"color:#393A34\">=</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">max</span><span class=\"token\" style=\"color:#393A34\">(</span><span>outputs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">1</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 4. Use correct `labels` and model `outputs` to calculate loss</span><span>\n</span><span>        loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">(</span><span>outputs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> labels</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 5. Compute gradients using the calculated loss</span><span>\n</span><span>        loss</span><span class=\"token\" style=\"color:#393A34\">.</span><span>backward</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 6. Use optimizer to update model parameters</span><span>\n</span><span>        optimizer</span><span class=\"token\" style=\"color:#393A34\">.</span><span>step</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Update variables keeping track of loss and correct predictions</span><span>\n</span><span>        running_loss </span><span class=\"token\" style=\"color:#393A34\">+=</span><span> loss</span><span class=\"token\" style=\"color:#393A34\">.</span><span>item</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">*</span><span> inputs</span><span class=\"token\" style=\"color:#393A34\">.</span><span>size</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">0</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>        running_corrects </span><span class=\"token\" style=\"color:#393A34\">+=</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">sum</span><span class=\"token\" style=\"color:#393A34\">(</span><span>preds </span><span class=\"token\" style=\"color:#393A34\">==</span><span> labels</span><span class=\"token\" style=\"color:#393A34\">.</span><span>data</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n        \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Calculate the average loss and average accuracy for the epoch</span><span>\n</span><span>    epoch_loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> running_loss </span><span class=\"token\" style=\"color:#393A34\">/</span><span> ds_size\n</span><span>    epoch_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> running_corrects</span><span class=\"token\" style=\"color:#393A34\">.</span><span>double</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">/</span><span> ds_size\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> epoch_loss</span><span class=\"token\" style=\"color:#393A34\">,</span><span> epoch_acc\n</span>    \n            \n        \n        \n<span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">eval_loop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> ds_size</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We put the model in evaluation mode</span><span>\n</span><span>    model</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">eval</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    running_loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0.0</span><span>\n</span><span>    running_corrects </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># The code used in the evaluation loop is very similar to that used</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># in the training loop.</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># The only difference is we use `torch.no_grad()` to ensure we</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># don&#x27;t compute any gradients while in evaluation mode.</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">with</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>no_grad</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>        </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> sample </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> dataloader</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>            inputs </span><span class=\"token\" style=\"color:#393A34\">=</span><span> sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;image&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>to</span><span class=\"token\" style=\"color:#393A34\">(</span><span>device</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>            labels </span><span class=\"token\" style=\"color:#393A34\">=</span><span> sample</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;label&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>to</span><span class=\"token\" style=\"color:#393A34\">(</span><span>device</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>            outputs </span><span class=\"token\" style=\"color:#393A34\">=</span><span> model</span><span class=\"token\" style=\"color:#393A34\">(</span><span>inputs</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>            _</span><span class=\"token\" style=\"color:#393A34\">,</span><span> preds </span><span class=\"token\" style=\"color:#393A34\">=</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">max</span><span class=\"token\" style=\"color:#393A34\">(</span><span>outputs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">1</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>            loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">(</span><span>outputs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> labels</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>            running_loss </span><span class=\"token\" style=\"color:#393A34\">+=</span><span> loss</span><span class=\"token\" style=\"color:#393A34\">.</span><span>item</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">*</span><span> inputs</span><span class=\"token\" style=\"color:#393A34\">.</span><span>size</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">0</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>            running_corrects </span><span class=\"token\" style=\"color:#393A34\">+=</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">sum</span><span class=\"token\" style=\"color:#393A34\">(</span><span>preds </span><span class=\"token\" style=\"color:#393A34\">==</span><span> labels</span><span class=\"token\" style=\"color:#393A34\">.</span><span>data</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>    epoch_loss </span><span class=\"token\" style=\"color:#393A34\">=</span><span> running_loss </span><span class=\"token\" style=\"color:#393A34\">/</span><span> ds_size\n</span><span>    epoch_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> running_corrects</span><span class=\"token\" style=\"color:#393A34\">.</span><span>double</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">/</span><span> ds_size\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> epoch_loss</span><span class=\"token\" style=\"color:#393A34\">,</span><span> epoch_acc\n</span>    \n\n\n<span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">train</span><span class=\"token\" style=\"color:#393A34\">(</span><span>\n</span><span>        model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> train_loader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> val_loader</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        epochs</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> optimizer</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        fine_tune</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">False</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>    \n<span>    train_start </span><span class=\"token\" style=\"color:#393A34\">=</span><span> time</span><span class=\"token\" style=\"color:#393A34\">.</span><span>time</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We save the model weights that give the best accuracy</span><span>\n</span><span>    best_model_wts </span><span class=\"token\" style=\"color:#393A34\">=</span><span> copy</span><span class=\"token\" style=\"color:#393A34\">.</span><span>deepcopy</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>state_dict</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    best_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0.0</span><span>\n</span>    \n<span>    </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> epoch </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> </span><span class=\"token builtin\">range</span><span class=\"token\" style=\"color:#393A34\">(</span><span>epochs</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>        \n<span>        epoch_start </span><span class=\"token\" style=\"color:#393A34\">=</span><span> time</span><span class=\"token\" style=\"color:#393A34\">.</span><span>time</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We run the training loop...</span><span>\n</span><span>        train_loss</span><span class=\"token\" style=\"color:#393A34\">,</span><span> train_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> train_loop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>\n</span><span>            model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> train_loader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            optimizer</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataset_sizes</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            fine_tune</span><span class=\"token\" style=\"color:#393A34\">=</span><span>fine_tune\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and then the validation loop...</span><span>\n</span><span>        val_loss</span><span class=\"token\" style=\"color:#393A34\">,</span><span> val_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> eval_loop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>\n</span><span>            model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> val_loader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataset_sizes</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n<span>        </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and save the model if it has the best validation accuracy so far</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> val_acc </span><span class=\"token\" style=\"color:#393A34\">&gt;</span><span> best_acc</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>            best_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> val_acc\n</span><span>            best_model_wts </span><span class=\"token\" style=\"color:#393A34\">=</span><span> copy</span><span class=\"token\" style=\"color:#393A34\">.</span><span>deepcopy</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>state_dict</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>            \n<span>        time_elapsed </span><span class=\"token\" style=\"color:#393A34\">=</span><span> time</span><span class=\"token\" style=\"color:#393A34\">.</span><span>time</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">-</span><span> epoch_start\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">f&#x27;Epoch: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">epoch</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">+</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#36acaa\">1</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">02</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\"> | Epoch Time: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">time_elapsed </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">//</span><span class=\"token string-interpolation token interpolation\"> </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#36acaa\">60</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.0f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">m </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">time_elapsed </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">%</span><span class=\"token string-interpolation token interpolation\"> </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#36acaa\">60</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.0f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">s&#x27;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">f&#x27;\\tTrain Loss: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">train_loss</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.3f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\"> | Train Acc: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">train_acc</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">*</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#36acaa\">100</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.2f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">%&#x27;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">f&#x27;\\t Val. Loss: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">val_loss</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.3f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\"> |  Val. Acc: </span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">{</span><span class=\"token string-interpolation token interpolation\">val_acc</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">*</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#36acaa\">100</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">:</span><span class=\"token string-interpolation token interpolation token format-spec\">.2f</span><span class=\"token string-interpolation token interpolation token\" style=\"color:#393A34\">}</span><span class=\"token string-interpolation token\" style=\"color:#A31515\">%&#x27;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>        \n        \n<span>    time_elapsed </span><span class=\"token\" style=\"color:#393A34\">=</span><span> time</span><span class=\"token\" style=\"color:#393A34\">.</span><span>time</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#393A34\">-</span><span> train_start\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&#x27;Training complete in {:.0f}m {:.0f}s&#x27;</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">format</span><span class=\"token\" style=\"color:#393A34\">(</span><span>\n</span><span>        time_elapsed </span><span class=\"token\" style=\"color:#393A34\">//</span><span> </span><span class=\"token\" style=\"color:#36acaa\">60</span><span class=\"token\" style=\"color:#393A34\">,</span><span> time_elapsed </span><span class=\"token\" style=\"color:#393A34\">%</span><span> </span><span class=\"token\" style=\"color:#36acaa\">60</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">print</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&#x27;Best val Acc: {:4f}&#x27;</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">format</span><span class=\"token\" style=\"color:#393A34\">(</span><span>best_acc</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Load the weights that gave the best accuracy</span><span>\n</span><span>    model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>load_state_dict</span><span class=\"token\" style=\"color:#393A34\">(</span><span>best_model_wts</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> model</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We create an instance of a <code>resnet50</code> model that we will use.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>model </span><span class=\"token\" style=\"color:#393A34\">=</span><span> models</span><span class=\"token\" style=\"color:#393A34\">.</span><span>resnet50</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>Since ResNet-50 is trained in ImageNet, it has 1000 outputs.</p>\n<p>We need to modify the fully connected layer so that the number of ouputs equals the number of classes we have in our dataset.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#008000;font-style:italic\"># Keep the same number of inputs,</span><span>\n</span><span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># but change the number of outputs to the number of unique labels in our dataset</span><span>\n</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>fc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> nn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Linear</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>fc</span><span class=\"token\" style=\"color:#393A34\">.</span><span>in_features</span><span class=\"token\" style=\"color:#393A34\">,</span><span> df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>label</span><span class=\"token\" style=\"color:#393A34\">.</span><span>unique</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">.</span><span>size</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#008000;font-style:italic\"># Use the power of the GPU! 💪</span><span>\n</span><span>device </span><span class=\"token\" style=\"color:#393A34\">=</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>device</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&quot;cuda:0&quot;</span><span> </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> torch</span><span class=\"token\" style=\"color:#393A34\">.</span><span>cuda</span><span class=\"token\" style=\"color:#393A34\">.</span><span>is_available</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#0000ff\">else</span><span> </span><span class=\"token\" style=\"color:#A31515\">&quot;cpu&quot;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>model </span><span class=\"token\" style=\"color:#393A34\">=</span><span> model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>to</span><span class=\"token\" style=\"color:#393A34\">(</span><span>device</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We now train the model for 10 epochs using the AdamW optimizer with default parameters.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>N_EPOCHS</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">10</span><span>\n</span>\n<span>criterion </span><span class=\"token\" style=\"color:#393A34\">=</span><span> nn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>CrossEntropyLoss</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>optimizer </span><span class=\"token\" style=\"color:#393A34\">=</span><span> optim</span><span class=\"token\" style=\"color:#393A34\">.</span><span>AdamW</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>parameters</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> weight_decay</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">0.1</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>model </span><span class=\"token\" style=\"color:#393A34\">=</span><span> train</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloaders</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloaders</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> N_EPOCHS</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> optimizer</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><code class=\"nteract-display-area-stdout\"><span>Epoch: 01 | Epoch Time: 3m 1s\n\tTrain Loss: 1.105 | Train Acc: 62.14%\n\t Val. Loss: 1.139 |  Val. Acc: 61.58%\nEpoch: 02 | Epoch Time: 3m 8s\n\tTrain Loss: 0.928 | Train Acc: 64.79%\n\t Val. Loss: 1.594 |  Val. Acc: 23.35%\nEpoch: 03 | Epoch Time: 3m 8s\n\tTrain Loss: 0.873 | Train Acc: 67.02%\n\t Val. Loss: 2.089 |  Val. Acc: 13.58%\nEpoch: 04 | Epoch Time: 3m 8s\n\tTrain Loss: 0.819 | Train Acc: 68.94%\n\t Val. Loss: 1.667 |  Val. Acc: 33.68%\nEpoch: 05 | Epoch Time: 3m 12s\n\tTrain Loss: 0.776 | Train Acc: 70.80%\n\t Val. Loss: 1.022 |  Val. Acc: 64.71%\nEpoch: 06 | Epoch Time: 3m 8s\n\tTrain Loss: 0.757 | Train Acc: 71.75%\n\t Val. Loss: 1.000 |  Val. Acc: 64.95%\nEpoch: 07 | Epoch Time: 3m 8s\n\tTrain Loss: 0.736 | Train Acc: 72.81%\n\t Val. Loss: 1.207 |  Val. Acc: 63.29%\nEpoch: 08 | Epoch Time: 3m 8s\n\tTrain Loss: 0.710 | Train Acc: 73.63%\n\t Val. Loss: 1.155 |  Val. Acc: 51.16%\nEpoch: 09 | Epoch Time: 3m 8s\n\tTrain Loss: 0.702 | Train Acc: 74.31%\n\t Val. Loss: 0.926 |  Val. Acc: 66.77%\nEpoch: 10 | Epoch Time: 3m 8s\n\tTrain Loss: 0.682 | Train Acc: 75.02%\n\t Val. Loss: 0.786 |  Val. Acc: 71.09%\n\nTraining complete in 31m 17s\nBest val Acc: 0.710914\n</span></code></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>The baseline model has an accuracy of 71.09%.</p>\n<h3>Higher resolution images during testing</h3>\n<p>The first way to use FixRes is by increasing the resolution of images at test time.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>test_sizes </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#36acaa\">64</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">128</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">224</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">384</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">480</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span>accuracy </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span></span><span class=\"token\" style=\"color:#0000ff\">for</span><span> size </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> test_sizes</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># For each of the test_sizes we</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 1. First resize the image to 1.25 the size we want during testing</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># 2. Take a CenterCrop of the desired size for testing</span><span>\n</span><span>    trans </span><span class=\"token\" style=\"color:#393A34\">=</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Compose</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">[</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Resize</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token builtin\">int</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">1.25</span><span> </span><span class=\"token\" style=\"color:#393A34\">*</span><span> size</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>CenterCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>size</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>ToTensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># We create a new dataset and dataloader with these transforms...</span><span>\n</span><span>    val_ds </span><span class=\"token\" style=\"color:#393A34\">=</span><span> CassavaDataset</span><span class=\"token\" style=\"color:#393A34\">(</span><span>df</span><span class=\"token\" style=\"color:#393A34\">[</span><span>df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>is_val </span><span class=\"token\" style=\"color:#393A34\">==</span><span> </span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>reset_index</span><span class=\"token\" style=\"color:#393A34\">(</span><span>drop</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;../train_images&#x27;</span><span class=\"token\" style=\"color:#393A34\">,</span><span> trans</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    ds_size </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token builtin\">len</span><span class=\"token\" style=\"color:#393A34\">(</span><span>val_ds</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    dataloader </span><span class=\"token\" style=\"color:#393A34\">=</span><span> DataLoader</span><span class=\"token\" style=\"color:#393A34\">(</span><span>val_ds</span><span class=\"token\" style=\"color:#393A34\">,</span><span> batch_size</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">64</span><span class=\"token\" style=\"color:#393A34\">,</span><span> shuffle</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">,</span><span> num_workers</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">4</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>    </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># ... and calculate the model&#x27;s accuracy</span><span>\n</span><span>    loss</span><span class=\"token\" style=\"color:#393A34\">,</span><span> acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> eval_loop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloader</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> ds_size</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    accuracy</span><span class=\"token\" style=\"color:#393A34\">.</span><span>append</span><span class=\"token\" style=\"color:#393A34\">(</span><span>acc</span><span class=\"token\" style=\"color:#393A34\">.</span><span>item</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We can then plot the different test sizes against the accuracy of the model to understand how the resolution of images at test time affects model accuracy.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">import</span><span> matplotlib</span><span class=\"token\" style=\"color:#393A34\">.</span><span>pyplot </span><span class=\"token\" style=\"color:#0000ff\">as</span><span> plt\n</span>\n<span>max_acc </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token builtin\">max</span><span class=\"token\" style=\"color:#393A34\">(</span><span>accuracy</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>max_res </span><span class=\"token\" style=\"color:#393A34\">=</span><span> test_sizes</span><span class=\"token\" style=\"color:#393A34\">[</span><span>accuracy</span><span class=\"token\" style=\"color:#393A34\">.</span><span>index</span><span class=\"token\" style=\"color:#393A34\">(</span><span>max_acc</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span>plt</span><span class=\"token\" style=\"color:#393A34\">.</span><span>plot</span><span class=\"token\" style=\"color:#393A34\">(</span><span>test_sizes</span><span class=\"token\" style=\"color:#393A34\">,</span><span> accuracy</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>plt</span><span class=\"token\" style=\"color:#393A34\">.</span><span>scatter</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">224</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">0.7109</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>plt</span><span class=\"token\" style=\"color:#393A34\">.</span><span>scatter</span><span class=\"token\" style=\"color:#393A34\">(</span><span>max_res</span><span class=\"token\" style=\"color:#393A34\">,</span><span> max_acc</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>plt</span><span class=\"token\" style=\"color:#393A34\">.</span><span>show</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><img alt=\"\" src=\"data:image/png;base64,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\" class=\"sc-bdVaJa jFcqvn\"/></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We can see that using a larger image resolution increases the accuracy from 71.09% (the blue dot) to 77.89% at a resolution of 384 (the orange dot).</p>\n<p>Note that using Resize (1.25 * 224) + CenterCrop (224) gives a higher accuracy than using just CenterCrop (224). This shows that the size of objects seen by the model is indeed different at test time and has an adverse effect on the accuracy.</p>\n<p>Also note that we have obtained a better accuracy from the model without even fine-tuning the model at a larger resolution!</p>\n<p>Let us now fine-tune the last layers of the model at a resolution of 384, since that&#x27;s the resolution at which the model performed best.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#008000;font-style:italic\"># Freeze all layers apart from the fully connected layer</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">for</span><span> name</span><span class=\"token\" style=\"color:#393A34\">,</span><span> child </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>named_children</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">if</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;fc&#x27;</span><span> </span><span class=\"token\" style=\"color:#0000ff\">not</span><span> </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> name</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> _</span><span class=\"token\" style=\"color:#393A34\">,</span><span> params </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> child</span><span class=\"token\" style=\"color:#393A34\">.</span><span>named_parameters</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>            params</span><span class=\"token\" style=\"color:#393A34\">.</span><span>requires_grad </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#36acaa\">False</span><span>\n</span>\n<span>data_transforms </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&#x27;train&#x27;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Compose</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">[</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>RandomResizedCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">384</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># RandomResizedCrop of size 384 during training</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>RandomHorizontalFlip</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>ToTensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#A31515\">&#x27;val&#x27;</span><span class=\"token\" style=\"color:#393A34\">:</span><span> transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Compose</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">[</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>Resize</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">480</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># First resize to 1.25 * 384 = 480</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>CenterCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">384</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#008000;font-style:italic\"># and then extract a CenterCrop of size 384</span><span>\n</span><span>            transforms</span><span class=\"token\" style=\"color:#393A34\">.</span><span>ToTensor</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        </span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">}</span><span>\n</span>\n<span>datasets </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_datasets</span><span class=\"token\" style=\"color:#393A34\">(</span><span>data_transforms</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>dataset_sizes </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">{</span><span>x</span><span class=\"token\" style=\"color:#393A34\">:</span><span> </span><span class=\"token builtin\">len</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">[</span><span>x</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">)</span><span> </span><span class=\"token\" style=\"color:#0000ff\">for</span><span> x </span><span class=\"token\" style=\"color:#0000ff\">in</span><span> </span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;train&#x27;</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#A31515\">&#x27;val&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">}</span><span>\n</span><span>dataloaders </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_dataloaders</span><span class=\"token\" style=\"color:#393A34\">(</span><span>datasets</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>criterion </span><span class=\"token\" style=\"color:#393A34\">=</span><span> nn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>CrossEntropyLoss</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>optimizer </span><span class=\"token\" style=\"color:#393A34\">=</span><span> optim</span><span class=\"token\" style=\"color:#393A34\">.</span><span>AdamW</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">.</span><span>parameters</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span> weight_decay</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">0.1</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span>model </span><span class=\"token\" style=\"color:#393A34\">=</span><span> train</span><span class=\"token\" style=\"color:#393A34\">(</span><span>model</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloaders</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;train&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> dataloaders</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&quot;val&quot;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span> </span><span class=\"token\" style=\"color:#36acaa\">5</span><span class=\"token\" style=\"color:#393A34\">,</span><span> criterion</span><span class=\"token\" style=\"color:#393A34\">,</span><span> optimizer</span><span class=\"token\" style=\"color:#393A34\">,</span><span> fine_tune</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">True</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><code class=\"nteract-display-area-stdout\"><span>Epoch: 01 | Epoch Time: 3m 20s\n\tTrain Loss: 0.650 | Train Acc: 76.00%\n\t Val. Loss: 0.582 |  Val. Acc: 79.46%\nEpoch: 02 | Epoch Time: 3m 22s\n\tTrain Loss: 0.642 | Train Acc: 76.78%\n\t Val. Loss: 0.587 |  Val. Acc: 79.67%\nEpoch: 03 | Epoch Time: 3m 22s\n\tTrain Loss: 0.632 | Train Acc: 76.88%\n\t Val. Loss: 0.588 |  Val. Acc: 79.67%\nEpoch: 04 | Epoch Time: 3m 23s\n\tTrain Loss: 0.644 | Train Acc: 76.59%\n\t Val. Loss: 0.589 |  Val. Acc: 79.53%\nEpoch: 05 | Epoch Time: 3m 23s\n\tTrain Loss: 0.640 | Train Acc: 76.72%\n\t Val. Loss: 0.585 |  Val. Acc: 79.46%\n\nTraining complete in 16m 50s\nBest val Acc: 0.796681\n</span></code></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>By passing <code>fine_tune=True</code> to the <code>train</code> method, we ensured that the entire model was in <code>eval</code> mode and just the last BatchNorm layer before the pooling layer was in <code>train</code> mode.</p>\n<p>And fine-tuning was indeed helpful! It bumped the accuracy of our model from 77.89% to 79.67%!</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h3>Lower resolution images during training</h3>\n<p>We could have used images with a lower resolution during training instead of increasing the resolution of images during testing.</p>\n<p>From the calculations in Table 1, we would use images of resolution 179x179 during training and images of resolution 224x224 during testing.</p>\n<p>Training the model with these resolutions is left as an exercise for the reader. 👀</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Transfer learning using fast.ai</h2>\n<p>The FixRes method can also be used with transfer learning. The authors mention that when fine-tuning a pre-trained model, they do the following:</p>\n<ol>\n<li>Initialize the model with pre-trained weights</li>\n<li>Train the entire model for several epochs at the training resolution</li>\n<li>Fine-tune the last BatchNorm and fully connected layer with a higher resolution</li>\n</ol>\n<p>We will try this approach with fast.ai.</p>\n<p>The code that follows was inspired by <a href=\"https://twitter.com/morgymcg\">@morgymcg</a>&#x27;s experiments available on GitHub: <a href=\"https://github.com/morganmcg1/fastgarden/blob/master/fixres_experiments.ipynb\">morganmcg1/fastgarden</a></p>\n<p>We will continue using the same dataset and the same train-test split described at the beginning of the PyTorch experiments.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span class=\"token\" style=\"color:#0000ff\">from</span><span> fastai</span><span class=\"token\" style=\"color:#393A34\">.</span><span>vision</span><span class=\"token\" style=\"color:#393A34\">.</span><span class=\"token builtin\">all</span><span> </span><span class=\"token\" style=\"color:#0000ff\">import</span><span> </span><span class=\"token\" style=\"color:#393A34\">*</span><span>\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># Define the path where the images are</span><span>\n</span><span>path </span><span class=\"token\" style=\"color:#393A34\">=</span><span> Path</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#A31515\">&#x27;..&#x27;</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># get_x fetches a single image</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">get_x</span><span class=\"token\" style=\"color:#393A34\">(</span><span>row</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> path</span><span class=\"token\" style=\"color:#393A34\">/</span><span class=\"token\" style=\"color:#A31515\">&#x27;train_images&#x27;</span><span class=\"token\" style=\"color:#393A34\">/</span><span>row</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;image_id&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># get_y fetches the label of a single image</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">get_y</span><span class=\"token\" style=\"color:#393A34\">(</span><span>row</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> row</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;label&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># The splitter returns the train/test split based on the</span><span>\n</span><span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># `is_val` column in our CSV file.</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">splitter</span><span class=\"token\" style=\"color:#393A34\">(</span><span>df</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>    train </span><span class=\"token\" style=\"color:#393A34\">=</span><span> df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>index</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#393A34\">~</span><span>df</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;is_val&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>tolist</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    valid </span><span class=\"token\" style=\"color:#393A34\">=</span><span> df</span><span class=\"token\" style=\"color:#393A34\">.</span><span>index</span><span class=\"token\" style=\"color:#393A34\">[</span><span>df</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#A31515\">&#x27;is_val&#x27;</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">.</span><span>tolist</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> train</span><span class=\"token\" style=\"color:#393A34\">,</span><span> valid\n</span>\n<span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># `get_dls` creates dataloaders with RandomResizedCrop of the specified size</span><span>\n</span><span></span><span class=\"token\" style=\"color:#008000;font-style:italic\"># and also with all the default augmentations</span><span>\n</span><span></span><span class=\"token\" style=\"color:#0000ff\">def</span><span> </span><span class=\"token\" style=\"color:#393A34\">get_dls</span><span class=\"token\" style=\"color:#393A34\">(</span><span>size</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">224</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">:</span><span>\n</span><span>    cassava </span><span class=\"token\" style=\"color:#393A34\">=</span><span> DataBlock</span><span class=\"token\" style=\"color:#393A34\">(</span><span>\n</span><span>        blocks </span><span class=\"token\" style=\"color:#393A34\">=</span><span> </span><span class=\"token\" style=\"color:#393A34\">(</span><span>ImageBlock</span><span class=\"token\" style=\"color:#393A34\">,</span><span> CategoryBlock</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        get_x</span><span class=\"token\" style=\"color:#393A34\">=</span><span>get_x</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        get_y</span><span class=\"token\" style=\"color:#393A34\">=</span><span>get_y</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        splitter</span><span class=\"token\" style=\"color:#393A34\">=</span><span>splitter</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        item_tfms</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#393A34\">[</span><span>RandomResizedCrop</span><span class=\"token\" style=\"color:#393A34\">(</span><span>size</span><span class=\"token\" style=\"color:#393A34\">,</span><span> min_scale</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">0.7</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">]</span><span class=\"token\" style=\"color:#393A34\">,</span><span>\n</span><span>        batch_tfms</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#393A34\">[</span><span class=\"token\" style=\"color:#393A34\">*</span><span>aug_transforms</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span class=\"token\" style=\"color:#393A34\">]</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    dls </span><span class=\"token\" style=\"color:#393A34\">=</span><span> cassava</span><span class=\"token\" style=\"color:#393A34\">.</span><span>dataloaders</span><span class=\"token\" style=\"color:#393A34\">(</span><span>df</span><span class=\"token\" style=\"color:#393A34\">,</span><span> bs</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">64</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>    </span><span class=\"token\" style=\"color:#0000ff\">return</span><span> dls</span></code></pre></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We create a ResNet-50 with pretrained weights and then train the entire network at a resolution of 224x224.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>dls </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_dls</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>learn </span><span class=\"token\" style=\"color:#393A34\">=</span><span> cnn_learner</span><span class=\"token\" style=\"color:#393A34\">(</span><span>dls</span><span class=\"token\" style=\"color:#393A34\">,</span><span> resnet50</span><span class=\"token\" style=\"color:#393A34\">,</span><span> metrics</span><span class=\"token\" style=\"color:#393A34\">=</span><span>accuracy</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>learn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>fine_tune</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">5</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><div><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.067555</td>\n      <td>0.806518</td>\n      <td>0.727506</td>\n      <td>02:55</td>\n    </tr>\n  </tbody>\n</table></div><div><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.675441</td>\n      <td>0.725409</td>\n      <td>0.757887</td>\n      <td>03:44</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.543039</td>\n      <td>0.556987</td>\n      <td>0.820986</td>\n      <td>03:44</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.463506</td>\n      <td>0.510089</td>\n      <td>0.833606</td>\n      <td>03:44</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.340905</td>\n      <td>0.478553</td>\n      <td>0.843188</td>\n      <td>03:44</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.276000</td>\n      <td>0.470489</td>\n      <td>0.849965</td>\n      <td>03:44</td>\n    </tr>\n  </tbody>\n</table></div></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>We then freeze the earlier layers of the model and fine-tune the last layer with a higher resolution.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-gzVnrw iiEGBE input-container\"><pre class=\"sc-bZQynM dQAqiJ input\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:10px 0px 10px 10px;margin:0px;overflow:auto;border:none;background-color:var(--cm-background, #fafafa)\"><code class=\"language-python\" style=\"color:#393A34;font-family:&quot;Consolas&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Courier New&quot;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;font-size:.9em;line-height:1.2em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none\"><span>new_dls </span><span class=\"token\" style=\"color:#393A34\">=</span><span> get_dls</span><span class=\"token\" style=\"color:#393A34\">(</span><span>size</span><span class=\"token\" style=\"color:#393A34\">=</span><span class=\"token\" style=\"color:#36acaa\">280</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>learn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>dls </span><span class=\"token\" style=\"color:#393A34\">=</span><span> new_dls\n</span><span>learn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>freeze</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#393A34\">)</span><span>\n</span><span>learn</span><span class=\"token\" style=\"color:#393A34\">.</span><span>fit</span><span class=\"token\" style=\"color:#393A34\">(</span><span class=\"token\" style=\"color:#36acaa\">5</span><span class=\"token\" style=\"color:#393A34\">)</span></code></pre></div><div class=\"sc-htoDjs fWFfJb nteract-outputs\" style=\"max-height:100%\"><div class=\"cell_display\" style=\"max-height:100%;overflow-y:auto\"><div><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.319706</td>\n      <td>0.466751</td>\n      <td>0.856509</td>\n      <td>04:38</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.298980</td>\n      <td>0.547480</td>\n      <td>0.825193</td>\n      <td>04:34</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.286727</td>\n      <td>0.461916</td>\n      <td>0.858378</td>\n      <td>04:34</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.280145</td>\n      <td>0.508987</td>\n      <td>0.841785</td>\n      <td>04:34</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.268317</td>\n      <td>0.517633</td>\n      <td>0.842253</td>\n      <td>04:34</td>\n    </tr>\n  </tbody>\n</table></div></div></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><p>This gives us a peak accuracy of 85.84%!</p>\n<p>The process is very similar to <a href=\"https://ravimashru.dev/blog/2021-08-11-fastbook-ch7/\">progressive resizing</a>. The difference is that with progressive resizing, we train the entire network with larger images. But with FixRes, we are just fine-tuning the last layers of the network with larger images.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Conclusion</h2>\n<p>Standard data augmentation techniques change the apparent size of objects during training.</p>\n<p>As a result, the model sees objects of different scale during training and testing. This is a problem because CNNs are not scale invariant.</p>\n<p>This can be remedied by training with smaller images, or testing with larger images.</p>\n<p>However, using images of different size at train time and test time negatively affects the classifier layers of the CNN.</p>\n<p>To address this, we fine tune the last few layers of the model, including the batch-norm layer preceding the global pooling layer at the higher resolution being used at test time.</p>\n<p>This approach can be used when training a model from scratch and also with transfer learning.</p></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>References</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1906.06423\">Fixing the train-test resolution discrepancy</a></li>\n<li><a href=\"https://github.com/facebookresearch/FixRes\">GitHub: facebookresearch/FixRes</a></li>\n<li><a href=\"https://www.ntentional.com/papers/training%20technique/classification/2020/04/15/fixres.html\">FixRes blog post by Morgan McGuire</a></li>\n</ul></div></div><div class=\"sc-bxivhb HLmih cell\" style=\"box-shadow:none\"><div class=\"sc-iwsKbI exQuEV markdown\"><h2>Acknowledgements</h2>\n<ul>\n<li><strong><a href=\"https://twitter.com/amaarora\">Aman Arora</a></strong> for the amazing <a href=\"https://community.wandb.ai/c/community-events/fastbook/8\">Fastbook reading group</a> sessions where he introduced this paper to us, for encouraging us to start reading research papers and for motivating us to actively write about what we learn in our deep learning journey.</li>\n<li><strong><a href=\"https://twitter.com/bhutanisanyam1\">Sanyam Bhutani</a></strong> for running the <a href=\"https://community.wandb.ai/c/community-events/pytorch-book/32\">PyTorch book reading group</a> sessions and encouraging us to have a bias towards action - writing code and trying things out instead of just reading. The PyTorch code I managed to write in this blog post is a result of the awesome study group he&#x27;s running.</li>\n<li><strong><a href=\"https://twitter.com/morgymcg\">Morgan McGuire</a></strong> for making his amazing <a href=\"https://github.com/morganmcg1/fastgarden/blob/master/fixres_experiments.ipynb\">fastgarden of FixRes experiments</a> available on GitHub which made it very easy for me to understand how to use FixRes with fastai.</li>\n</ul></div></div></div></div>","json":{"metadata":{"title":"Understanding FixRes - Fixing the train-test resolution discrepancy","date":"2021-09-22"}}}},"pageContext":{"id":"a5ddaf24-8d02-5505-8cb3-33549fb3fbb3 >>> JupyterNotebook"}},"staticQueryHashes":["3069025275","63159454"]}